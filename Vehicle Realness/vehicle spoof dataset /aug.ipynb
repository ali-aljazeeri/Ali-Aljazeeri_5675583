{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_W_EDef73mp",
        "outputId": "1f5b1a58-bae5-4e07-b176-0e0b0cba67fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Augmenting training data...\n",
            "Augmenting validation data...\n",
            "Augmenting test data...\n",
            "Dataset preparation completed.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import random\n",
        "\n",
        "def load_images_by_class(input_folder, class_name):\n",
        "    images = [f for f in os.listdir(input_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]\n",
        "    image_paths = [(os.path.join(input_folder, img), class_name) for img in images]\n",
        "    return image_paths\n",
        "\n",
        "def split_data_balanced(class_data, train_ratio=0.7, val_ratio=0.15):\n",
        "    random.shuffle(class_data)\n",
        "    total = len(class_data)\n",
        "    train_end = int(train_ratio * total)\n",
        "    val_end = train_end + int(val_ratio * total)\n",
        "    return {\n",
        "        \"train\": class_data[:train_end],\n",
        "        \"val\": class_data[train_end:val_end],\n",
        "        \"test\": class_data[val_end:]\n",
        "    }\n",
        "\n",
        "def resize_by_width(img, target_width=1000):\n",
        "    h, w = img.shape[:2]\n",
        "    scale = target_width / w\n",
        "    new_h = int(h * scale)\n",
        "    resized = cv2.resize(img, (target_width, new_h), interpolation=cv2.INTER_AREA)\n",
        "    return resized\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def center_crop(img, crop_ratio=0.8):\n",
        "    h, w = img.shape[:2]\n",
        "    ch, cw = int(h * crop_ratio), int(w * crop_ratio)\n",
        "    start_x = (w - cw) // 2\n",
        "    start_y = (h - ch) // 2\n",
        "    return img[start_y:start_y+ch, start_x:start_x+cw]\n",
        "\n",
        "def adjust_brightness_contrast(img, brightness=30, contrast=30):\n",
        "    beta = np.random.randint(-brightness, brightness)\n",
        "    alpha = 1.0 + (np.random.rand() * contrast / 100.0) * random.choice([-1, 1])\n",
        "    img_bc = cv2.convertScaleAbs(img, alpha=alpha, beta=beta)\n",
        "    return img_bc\n",
        "\n",
        "def random_affine_transform(img):\n",
        "    rows, cols = img.shape[:2]\n",
        "    pts1 = np.float32([[5,5], [cols-5,5], [5,rows-5]])\n",
        "    pts2 = pts1 + np.random.randint(-15, 15, pts1.shape).astype(np.float32)\n",
        "    M = cv2.getAffineTransform(pts1, pts2)\n",
        "    return cv2.warpAffine(img, M, (cols, rows))\n",
        "\n",
        "def augment_and_save(image_list, output_folder):\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    scale_widths = [600, 800, 1000]\n",
        "\n",
        "    for src_path, label in image_list:\n",
        "        img = cv2.imread(src_path)\n",
        "        if img is None:\n",
        "            print(f\"Warning: Could not read {src_path}\")\n",
        "            continue\n",
        "\n",
        "        name, ext = os.path.splitext(os.path.basename(src_path))\n",
        "\n",
        "        for idx, width in enumerate(scale_widths):\n",
        "            base_img = resize_by_width(img, target_width=width)\n",
        "\n",
        "            # Augmentation set\n",
        "            augmentations = [\n",
        "                (\"0\", base_img),  # Original scaled\n",
        "                (\"1\", center_crop(base_img)),  # Center cropped\n",
        "                (\"2\", cv2.rotate(base_img, cv2.ROTATE_180)),  # Rotated\n",
        "                (\"3\", cv2.flip(base_img, 1)),  # Horizontal flip\n",
        "                (\"4\", adjust_brightness_contrast(base_img)),  # Brightness/contrast\n",
        "                (\"5\", random_affine_transform(base_img)),  # Affine transform\n",
        "            ]\n",
        "\n",
        "            for aug_code, aug_img in augmentations:\n",
        "                out_name = f\"{label}_{name}_s{idx}_{aug_code}{ext}\"\n",
        "                out_path = os.path.join(output_folder, out_name)\n",
        "                cv2.imwrite(out_path, aug_img)\n",
        "\n",
        "\n",
        "def prepare_dataset(real_folder, not_real_folder, output_base):\n",
        "    # Load class-wise images\n",
        "    real_images = load_images_by_class(real_folder, \"real\")\n",
        "    not_real_images = load_images_by_class(not_real_folder, \"not_real\")\n",
        "\n",
        "    # Shuffle each class list before splitting\n",
        "    random.shuffle(real_images)\n",
        "    random.shuffle(not_real_images)\n",
        "\n",
        "    # Split with class balance\n",
        "    real_split = split_data_balanced(real_images)\n",
        "    not_real_split = split_data_balanced(not_real_images)\n",
        "\n",
        "    # Merge splits\n",
        "    train_data = real_split[\"train\"] + not_real_split[\"train\"]\n",
        "    val_data = real_split[\"val\"] + not_real_split[\"val\"]\n",
        "    test_data = real_split[\"test\"] + not_real_split[\"test\"]\n",
        "\n",
        "    # Shuffle final combined splits\n",
        "    random.shuffle(train_data)\n",
        "    random.shuffle(val_data)\n",
        "    random.shuffle(test_data)\n",
        "\n",
        "    # Augment and save\n",
        "    print(\"Augmenting training data...\")\n",
        "    augment_and_save(train_data, os.path.join(output_base, \"train\"))\n",
        "\n",
        "    print(\"Augmenting validation data...\")\n",
        "    augment_and_save(val_data, os.path.join(output_base, \"val\"))\n",
        "\n",
        "    print(\"Augmenting test data...\")\n",
        "    augment_and_save(test_data, os.path.join(output_base, \"test\"))\n",
        "\n",
        "    print(\"Dataset preparation completed.\")\n",
        "\n",
        "# main\n",
        "real_input = \"./final dataset/real\"\n",
        "not_real_input = \"./final dataset/not_real\"\n",
        "output_folder = \"./data random/split\"\n",
        "\n",
        "prepare_dataset(real_input, not_real_input, output_folder)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}